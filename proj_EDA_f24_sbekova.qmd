---
title: "Exploratory Data Analysis"
author: "Saniya Bekova"
date: "10/14/2024"
format: 
  pdf:
    code-line-wrap: true
    listing-options:
      breaklines: true
      breakatwhitespace: true
      frame: single
editor: source
---

```{r load necessary libraries}
#| message: false
#| warning: false
#load necessary libraries
library(tidyverse)
library(readxl)
library(haven) #for loading other datafiles (SAS, STATA, SPSS, etc.)
library(stringr)
library(lubridate)
library(ggplot2)
library(dplyr)
library(ggrepel)
library(scales)
library(tidymodels)

```

```{r load data}
#| message: false
#| warning: false
#load data
education_data <- read_csv('data/education_data.csv')  # Dataset 1: Educational indicators
imo_data <- read_csv('data/imo_data.csv')  # Dataset 2: IMO competition results
```

## Main Outcome/Target (Y Variable):

The main outcome or target variable in this analysis is the **average score per contestant for each country in a given year**. This is calculated by summing the scores from problems 1 to 7 for each country’s team and dividing the total by the number of participants (team_size_all). This variable represents how well the entire team from each country performed in the International Mathematical Olympiad (IMO).

This outcome is a good fit for the study because it provides a clear measure of how well a country’s education system prepares students for international competitions. By using the average score, the analysis captures the performance of the whole team, not just the top individual performers. This is important for understanding the impact of educational investments, such as government spending on education, literacy rates, and school completion rates, on a country’s success in the IMO.

The average score per contestant gives a more detailed and fair comparison between countries. It helps to evaluate the overall strength of the team, making it a useful measure for examining how education systems contribute to performance in international competitions.

By focusing on the average score, this analysis can effectively explore the connection between educational investments and a country’s overall performance in the IMO, making it a suitable target for this project.

## Data Cleaning

```{r loading new data for literacy rate}
#| message: false
#| warning: false
literacy_rate_by_country_and_region <- read_csv("data/literacy_data.csv")

country_and_region_data <- read_xlsx("data/P_Data_Extract_From_Education_Statistics_-_All_Indicators_Metadata.xlsx", sheet = "Country - Metadata")

youth_literacy_rate <- literacy_rate_by_country_and_region |>
  filter(Series == "Youth literacy rate, population 15-24 years, both sexes (%)")

youth_literacy_rate <- pivot_longer(youth_literacy_rate, 
                                   cols = c('2009 [YR2009]', '2010 [YR2010]', '2011 [YR2011]', '2012 [YR2012]', '2013 [YR2013]', '2014 [YR2014]', '2015 [YR2015]', '2016 [YR2016]', '2017 [YR2017]', '2018 [YR2018]', '2019 [YR2019]'), 
                                   names_to = "Year",                  
                                   values_to = "Literacy_Rate") |>
  mutate(Year = str_replace(Year, " \\[YR[0-9]+\\]", "")) |>
  select("Country Code", "Country Name", Year, Literacy_Rate)

youth_literacy_rate <- youth_literacy_rate |>
  mutate(Year = as.double(Year),
         Literacy_Rate = as.double(Literacy_Rate))


education_data_joined <- education_data |>
  left_join(youth_literacy_rate, 
            by = c("Country" = "Country Name", "Year" = "Year"), 
            suffix = c("", "_new"))

education_data_updated <- education_data_joined |>
  mutate(Value_literacy_rate = coalesce(Value_literacy_rate, 
                                        Literacy_Rate)) |>
  select(-Literacy_Rate)
  
```

```{r}
#| message: false
#| warning: false
education_with_region <- education_data_updated |>
  left_join(country_and_region_data, by = c("Country" = "Long Name"))

education_full <- education_with_region |>
  left_join(youth_literacy_rate, 
            by = c("Region" = "Country Name", "Year" = "Year"),  
            suffix = c("", "_region")) |>
  left_join(youth_literacy_rate, 
            by = c("Country" = "Country Name", "Year" = "Year"), 
            suffix = c("", "_country")) |>
  left_join(youth_literacy_rate,
            by = c("Income Group" = "Country Name", "Year" = "Year"), 
            suffix = c("", "_income"))

education_data_updated <- education_full |>
  mutate(Value_literacy_rate = coalesce(Value_literacy_rate, 
                                        Literacy_Rate_country, 
                                        Literacy_Rate)) |>
  select(-Literacy_Rate_country, -Literacy_Rate)  

education_data_updated <- education_data_updated |>
  mutate(Value_literacy_rate = coalesce(Value_literacy_rate, 
                                        Literacy_Rate_income)) |>
  select(Country, 
         Year, 
         `Country Code`, 
         Value_gross_enr_ratio_for_tertirary_edu,
         Value_gov_expen_as_perc_of_GPP, 
         Value_literacy_rate, 
         Region, 
         `Income Group`)


```

Merging Educational Data:

The educational indicators from the UNESCO Institute for Statistics were split across multiple variables (e.g., primary and secondary education completion rates, government expenditure on education). These were merged into a single dataset, ensuring all relevant indicators were available for each country and year. The merging process involved handling mismatched country names between the datasets. For example, differences such as "Kyrgyz Republic" vs. "Kyrgyzstan" were corrected manually to ensure proper alignment of the data.

Combining IMO Data with Educational Data:

The educational data (which now included literacy rates, completion rates, and government expenditure) was merged with the IMO performance data (e.g., team scores, medals won) to create a comprehensive dataset. This allowed for the analysis of the relationship between a country’s educational indicators and its performance in the IMO.

## Creating New Variables :

`Medal_Efficiency` This variable was created by dividing the total number of medals (gold, silver, and bronze) won by a country by its team size (team_size_all). It measures how efficiently a country converts its team into medals, providing insights into performance relative to team size.

`Gov_Investment_Per_Medal` This variable measures the amount of government expenditure on education required to produce one IMO medal. It was created by dividing the government expenditure as a percentage of GDP by the total number of medals won.

`Lit_Performance_Ratio` This variable measures the ratio between a country’s youth literacy rate and its average IMO score or total number of medals won, helping to explore the link between literacy and performance.

These variables were created before the training-test split to avoid any issues related to leakage between the datasets.

```{r new variables}
#| message: false
#| warning: false
# Calculate total score by summing problem scores p1 to p7
imo_data <- imo_data |>
  rowwise() |>
  mutate(total_score = sum(c_across(p1:p7), na.rm = TRUE)) |>
  ungroup()  

# Calculate average score per contestant by dividing total score by team size
imo_data <- imo_data |>
  mutate(average_score_per_contestant = total_score / team_size_all)

imo_data <- imo_data |>
  mutate(medal_Efficiency = ifelse(team_size_all > 0, 
                                   (awards_gold + awards_silver + awards_bronze) / team_size_all, 
                                   NA))

# Merging 'imo_data' with 'education_data_updated'
combined_data <- imo_data |>
  left_join(education_data_updated, by = c("country" = "Country", "year" = "Year"))

combined_data <- combined_data |>
  mutate(Gov_Investment_Per_Medal = ifelse((awards_gold + awards_silver + awards_bronze) > 0, 
                                           Value_gov_expen_as_perc_of_GPP / (awards_gold + awards_silver + awards_bronze), 
                                           NA),
         Lit_Performance_Ratio = ifelse(average_score_per_contestant > 0, 
                                        Value_literacy_rate / average_score_per_contestant, 
                                        NA))

combined_data <- combined_data |>
  filter(year > 2008 & year < 2020)


summary(combined_data)

write_csv(combined_data, "data/combined_data.csv")


```
## Split data
```{r train and test split}
set.seed(1234)
combined_data_split <- initial_split(combined_data, prop = 3/4, strata = Value_gov_expen_as_perc_of_GPP)
train_data <- training(combined_data_split)
test_data <- testing(combined_data_split)
```

## After a training-test split

## Scaling
```{r}
# Calculate mean and standard deviation on the training set for standardization
gdp_mean <- mean(train_data$Value_gov_expen_as_perc_of_GPP, na.rm = TRUE)
gdp_sd <- sd(train_data$Value_gov_expen_as_perc_of_GPP, na.rm = TRUE)

# Standardize training data using training set statistics
train_data$Value_gov_expen_as_perc_of_GPP <- (train_data$Value_gov_expen_as_perc_of_GPP - gdp_mean) / gdp_sd

# Apply the same standardization to the test data 
test_data$Value_gov_expen_as_perc_of_GPP <- (test_data$Value_gov_expen_as_perc_of_GPP - gdp_mean) / gdp_sd

```


## Excluded Observations

Observations from years prior to 2009 and after 2019 were excluded due to insufficient data availability.

Additionally, certain features were excluded due to a significant number of missing values (approximately 1,500 NAs out of 1,999 total observations). These features included:

1.  Completion rate, primary education, both sexes (%)

2.  Completion rate, lower secondary education, both sexes (%)

3.  Completion rate, upper secondary education, both sexes (%)

Since no relevant data was available to fill the missing values, these features were omitted from the analysis.

## Handling missing data

The summary showed that the literacy_rate feature had about 1,500 missing values, indicating that we lacked sufficient data. To address this, I sourced an additional dataset for literacy rates from the World Bank (https://databank.worldbank.org/source/education-statistics-%5e-all-indicators ). When missing data was'nt found for a specific country, the missing NA values were replaced with regional data. After all of these if we have NA's it will be replaced with mean value
```{r}
train_data$Value_literacy_rate[is.na(train_data$Value_literacy_rate)] <- mean(train_data$Value_literacy_rate, na.rm = TRUE)
test_data$Value_literacy_rate[is.na(test_data$Value_literacy_rate)] <- mean(test_data$Value_literacy_rate, na.rm = TRUE)
```

## Data Visualization
## 1.Scatter Plot: Government Expenditure vs. Average Score Per Contestant
This plot shows the relationship between government spending on education (as a percentage of GDP) and the average score achieved by a country’s team in the IMO.
```{r}
#| message: false
#| warning: false
# Scatter plot of government expenditure vs. average score per contestant
ggplot(train_data, aes(x = Value_gov_expen_as_perc_of_GPP, y = average_score_per_contestant)) +
  geom_point(alpha = 0.7, color = "#615e9b") +
  geom_smooth(method = "lm", color = "#ff9e1b", se = FALSE) +
  ggtitle("Government Expenditure vs. Average IMO Score per Contestant") +
  xlab("Government Expenditure as % of GDP") +
  ylab("Average Score per Contestant") +
  scale_x_continuous(labels = label_percent(suffix = "%", scale = 1)) +
  theme_minimal()

```
Interpretation: The plot indicates that government expenditure on education as a percentage of GDP does not have a significant correlation with average IMO scores. This suggests that simply increasing spending may not lead to better performance in mathematics competitions.


## 2.Line Plot: Medal Counts of the Top 3 Countries in 2019 Over the Period 2009–2019
This line plot displays the total number of medals won by the top 3 countries from 2009 to 2019, selected based on their medal counts in 2019. Each line represents a country and tracks its medal achievements over time. The colors of the lines correspond to different countries, and the labels for each country are positioned next to the last point (2019) for easy identification. This visualization allows us to observe the trend and consistency of each country's performance in terms of medal counts over the 10-year period.
```{r}
library(ggrepel)
#| message: false
#| warning: false

# 1) Selecting the top 3 countries by the number of medals in 2019
top_countries_2019 <- train_data |>
  filter(year == 2019) |>
  group_by(country) |>
  summarize(total_medals_2019 = sum(awards_gold + awards_silver + awards_bronze, na.rm = TRUE)) |>
  arrange(desc(total_medals_2019)) |>
  slice_head(n = 3) |>
  pull(country)

# 2) Filtering data for the selected countries from 2009 to 2019
medal_data <- train_data |>
  filter(country %in% top_countries_2019, year >= 2009, year <= 2019) |>
  group_by(year, country) |>
  summarize(total_medals = sum(awards_gold + awards_silver + awards_bronze, na.rm = TRUE)) |>
  ungroup()

# Set colors for each country
country_colors <- setNames(c("#615e9b", "#ff9e1b", "#44693d"), top_countries_2019)

# Plot the graph
ggplot(medal_data, aes(x = year, y = total_medals, color = country, group = country)) +
  geom_line(size = 1.5) + # Line for each country
  geom_point(size = 3) + # Points on the lines
  scale_color_manual(values = country_colors) +
  scale_x_continuous(breaks = seq(2009, 2019, by = 1), labels = as.character(seq(2009, 2019, by = 1))) +
  labs(
    title = "Medal Counts of the Top 3 Countries in 2019 ",
    subtitle = "Over the Period 2009–2019",
    x = "Year",
    y = "Total Medals",
    color = "Country"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    panel.grid.major = element_line(color = "gray80", size = 0.5),
    panel.grid.minor = element_blank(),
    legend.position = "none" # Remove legend for cleaner design
  ) +
 # Add annotations for each country next to the latest values
  geom_text_repel(data = medal_data %>% filter(year == 2019), 
                  aes(label = country), 
                  nudge_x = 0.9, # Slightly shift text to the right
                  direction = "y", # Repel text in the y direction
                  size = 3, fontface = "bold", color = country_colors)


```
## 3.Density plot: Distribution of Average IMO Scores by Literacy Rate Ranges
```{r}
#| message: false
#| warning: false

# Density plot showing the distribution of average scores by literacy rate
ggplot(train_data, aes(x = average_score_per_contestant, fill = cut(Value_literacy_rate, breaks = seq(90, 100, by = 2)))) +
  geom_density(alpha = 0.6) +
  scale_fill_brewer(palette = "Blues", name = "Literacy Rate Range (%)") +
  labs(
    title = "Distribution of Average IMO Scores by Literacy Rate Ranges",
    x = "Average Score per Contestant",
    y = "Density"
  ) +
  theme_minimal()


```
Interpretation: 

The plot suggests that literacy rate does not strongly impact the distribution of average IMO scores per contestant. Countries with both lower and higher literacy rates show similar distributions of average scores, implying that literacy rate alone does not significantly influence IMO performance.

## 4.Boxplot: Compares the average IMO scores between countries with and without female team members:
```{r}
#| message: false
#| warning: false

train_data_fem <- train_data |>
  mutate(
    team_size_female = ifelse(is.na(team_size_female), 0, team_size_female), # Treat NA as 0
    has_female_team = ifelse(team_size_female > 0, "With Female Team", "Without Female Team")
  )

ggplot(train_data_fem, aes(x = has_female_team, y = average_score_per_contestant, fill = has_female_team)) +
  geom_boxplot() +
  labs(
    title = "Average IMO Score per Contestant by Female Team Presence",
    x = "Female Team Presence",
    y = "Average Score per Contestant"
  ) +
  scale_fill_manual(values = c("With Female Team" = "#F28E2B", "Without Female Team" = "#4E79A7")) +
  theme_minimal() +
  theme(legend.position = "none")

```
The plot suggests a slight association between the absence of female team members and higher average IMO scores, although the difference is not very large. 



